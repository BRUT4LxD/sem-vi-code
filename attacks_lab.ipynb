{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from architectures.sample_conv import ConvNetMNIST, ConvNetCIFAR\n",
    "from data_eng.dataset_loader import load_MNIST, load_imagenette, load_CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from data_eng.io import load_model\n",
    "from evaluation.metrics import evaluate_attack, evaluate_model\n",
    "from attacks.pgd_mn import PGD_MN\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6976b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "MODEL_SAVE_PATH = './models/cnn-cifar.pt'\n",
    "\n",
    "model = load_model(ConvNetCIFAR().to(device), MODEL_SAVE_PATH)\n",
    "\n",
    "_, test_loader = load_CIFAR10(test_subset_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7352dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input must have a range [0, 1] (max: 1.0, min: -0.9529411792755127)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m atk \u001b[38;5;241m=\u001b[39m FGSM(model, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m      7\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 8\u001b[0m adv_images \u001b[38;5;241m=\u001b[39m \u001b[43matk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# acc = clean_accuracy(model, adv_images, labels)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BRUT4LxD\\OneDrive - Wojskowa Akademia Techniczna\\Pulpit\\Moje\\Uczelnia\\Studia doktoranckie\\SEM VI\\sem-vi-code\\attacks\\attack.py:455\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[1;34m(self, images, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m given_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[0;32m    454\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_change_model_mode(given_training)\n\u001b[1;32m--> 455\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_inputs(images)\n\u001b[0;32m    456\u001b[0m adv_images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(images, labels, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    457\u001b[0m adv_images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_outputs(adv_images)\n",
      "File \u001b[1;32mc:\\Users\\BRUT4LxD\\OneDrive - Wojskowa Akademia Techniczna\\Pulpit\\Moje\\Uczelnia\\Studia doktoranckie\\SEM VI\\sem-vi-code\\attacks\\attack.py:70\u001b[0m, in \u001b[0;36mAttack._check_inputs\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     68\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_normalize(images)\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mmax(images) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\u001b[39m+\u001b[39mtol \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39mmin(images) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m\u001b[39m-\u001b[39mtol:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInput must have a range [0, 1] (max: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, min: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     71\u001b[0m         torch\u001b[39m.\u001b[39mmax(images), torch\u001b[39m.\u001b[39mmin(images)))\n\u001b[0;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m images\n",
      "\u001b[1;31mValueError\u001b[0m: Input must have a range [0, 1] (max: 1.0, min: -0.9529411792755127)"
     ]
    }
   ],
   "source": [
    "from attacks.fgsm import FGSM\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = torch.clamp(images, 0, 1).to(device)\n",
    "    labels = labels.to(device)\n",
    "    atk = FGSM(model, eps=8/255)\n",
    "    start = datetime.datetime.now()\n",
    "    adv_images = atk(images, labels)\n",
    "    end = datetime.datetime.now()\n",
    "    # acc = clean_accuracy(model, adv_images, labels)\n",
    "    print('- Robust Acc: {} ({} ms)'.format(0, int((end-start).total_seconds()*1000)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a745e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = PGD_MN(model)\n",
    "attack_results = att.forward(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08fe9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.63, Precision: 91.05, Recall: 89.44, F1: 89.7\n",
      "[[ 881    8    5    4   21    7    7    5   10   19]\n",
      " [   0 1133    0    0    0    0    0    1    0    0]\n",
      " [   2   44  888    8    6    0    1   12   65    0]\n",
      " [   0   35    6  817    2    3    0    0  109   20]\n",
      " [   1   26    3    0  926    0    1    2   12    0]\n",
      " [   2   17    1   18    1  726   11    4   84    6]\n",
      " [   2   28    5    1   39    4  856    0    9    1]\n",
      " [   2   32   15    1    5    0    0  927   14    6]\n",
      " [   3    8    5    0    6    2    3    2  926    3]\n",
      " [   3   10    2    2  121    2    0   26   70  743]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attack_eval = evaluate_attack(attack_results, 10)\n",
    "\n",
    "print(attack_eval)\n",
    "print(attack_eval.conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ae858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425d6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd697d880e25f9a19415c9beca2cc6c48bd734e4d3b405ba26ef343dcc073325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
