import os
from datetime import datetime
from typing import Dict, List

from config.imagenet_models import ImageNetModels
from data_eng.dataset_loader import load_attacked_imagenette
from imagenette_lab.imagenette_base_trainer import BaseImageNetteTrainer
from training.train import Training


class ImageNetteNoiseDetectionTrainer(BaseImageNetteTrainer):
    """
    Noise detection training for ImageNette adversarial vs clean classification.
    """

    def train_noise_detection_model(
        self,
        model_name: str,
        attacked_images_folder: str = "data/attacks/imagenette_models",
        clean_train_folder: str = "./data/imagenette/train",
        clean_test_folder: str = "./data/imagenette/val",
        batch_size: int = 32,
        learning_rate: float = 0.001,
        num_epochs: int = 20,
        early_stopping_patience: int = 7,
        scheduler_type: str = 'plateau',
        weight_decay: float = 0.0001,
        gradient_clip_norm: float = 1.0,
        verbose: bool = True
    ) -> Dict:
        """
        Train a binary classifier to detect adversarial noise in ImageNette images.

        This method trains a model to distinguish between clean and adversarial images
        using the attacked ImageNette dataset generated by attack_and_save_images_multiple
        from imagenette_adv_imgs_generator.

        Args:
            model_name: Name of the model architecture to use
            attacked_images_folder: Folder containing attacked images from all models
            clean_train_folder: Folder containing clean ImageNette training images
            clean_test_folder: Folder containing clean ImageNette validation images
            batch_size: Batch size for training
            learning_rate: Initial learning rate
            num_epochs: Maximum number of training epochs
            early_stopping_patience: Epochs to wait before early stopping
            scheduler_type: Learning rate scheduler ('plateau', 'step', 'cosine')
            weight_decay: L2 regularization weight
            gradient_clip_norm: Gradient clipping threshold (None to disable)
            verbose: Whether to print detailed progress

        Returns:
            dict: Training results including model, metrics, and metadata
        """
        print(f"\n{'='*70}")
        print(f"ğŸ” Training Noise Detection Model: {model_name}")
        print(f"{'='*70}")

        try:
            # Validate model name
            if model_name not in self.AVAILABLE_MODELS:
                available_models = ', '.join(self.AVAILABLE_MODELS)
                raise ValueError(f"Model '{model_name}' not available. Available models: {available_models}")

            # Load attacked ImageNette dataset
            print("\nğŸ“ Loading attacked ImageNette dataset for binary classification...")
            train_loader, test_loader = load_attacked_imagenette(
                attacked_images_folder=attacked_images_folder,
                clean_train_folder=clean_train_folder,
                clean_test_folder=clean_test_folder,
                batch_size=batch_size,
                shuffle=True
            )

            # Create fresh model instance
            print(f"\nğŸ”§ Creating {model_name} model instance...")
            model = ImageNetModels.get_model(model_name)

            # Setup save path
            save_path = os.path.join(self.noise_detection_dir, f"{model_name}_noise_detector.pt")

            # Train noise detection model
            print("\nğŸš€ Starting noise detection training...")
            start_time = datetime.now()

            training_results = Training.train_imagenette_noise_detection(
                model=model,
                train_loader=train_loader,
                test_loader=test_loader,
                learning_rate=learning_rate,
                num_epochs=num_epochs,
                device=str(self.device),
                save_model_path=save_path,
                model_name=model_name,
                writer=None,  # TensorBoard writer will be created automatically
                setup_model=True,  # Automatically setup for binary classification
                validation_frequency=1,
                early_stopping_patience=early_stopping_patience,
                min_delta=0.001,
                scheduler_type=scheduler_type,
                scheduler_params=None,
                gradient_clip_norm=gradient_clip_norm,
                weight_decay=weight_decay,
                verbose=verbose
            )

            training_time = (datetime.now() - start_time).total_seconds()

            # Print results summary
            print("\nâœ… Noise detection training completed successfully!")
            print(f"   Training time: {training_time:.2f}s ({training_time/60:.2f} minutes)")
            print(f"   Best validation accuracy: {training_results['best_val_accuracy']:.2f}%")
            print(f"   Best precision: {training_results['best_precision']:.2f}%")
            print(f"   Best recall: {training_results['best_recall']:.2f}%")
            print(f"   Best F1 score: {training_results['best_f1']:.2f}%")
            print(f"   Model saved to: {save_path}")

            return {
                'model_name': model_name,
                'task': 'noise_detection',
                'training_results': training_results,
                'training_time': training_time,
                'save_path': save_path,
                'attacked_images_folder': attacked_images_folder,
                'clean_train_folder': clean_train_folder,
                'clean_test_folder': clean_test_folder,
                'batch_size': batch_size,
                'learning_rate': learning_rate,
                'num_epochs': num_epochs,
                'best_val_accuracy': training_results['best_val_accuracy'],
                'best_precision': training_results['best_precision'],
                'best_recall': training_results['best_recall'],
                'best_f1': training_results['best_f1'],
                'success': True
            }

        except Exception as e:
            error_msg = f"Noise detection training failed: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return {
                'model_name': model_name,
                'task': 'noise_detection',
                'error': error_msg,
                'success': False
            }

    def train_multiple_noise_detectors(
        self,
        model_names: List[str],
        attacked_images_folder: str = "data/attacks/imagenette_models",
        clean_train_folder: str = "./data/imagenette/train",
        clean_test_folder: str = "./data/imagenette/val",
        batch_size: int = 32,
        learning_rate: float = 0.001,
        num_epochs: int = 20
    ) -> List[Dict]:
        """
        Train multiple models for noise detection.

        Args:
            model_names: List of model names to train
            attacked_images_folder: Folder containing attacked images
            clean_train_folder: Folder containing clean training images
            clean_test_folder: Folder containing clean validation images
            batch_size: Batch size for training
            learning_rate: Learning rate for all models
            num_epochs: Number of epochs for all models

        Returns:
            List of training results for each model
        """
        print(f"\n{'='*70}")
        print("ğŸš€ Training Multiple Noise Detection Models")
        print(f"{'='*70}")
        print(f"   Models: {len(model_names)}")
        print(f"   Attacked images folder: {attacked_images_folder}")

        results = []

        for i, model_name in enumerate(model_names, 1):
            print(f"\nğŸ“Š Model {i}/{len(model_names)}: {model_name}")

            result = self.train_noise_detection_model(
                model_name=model_name,
                attacked_images_folder=attacked_images_folder,
                clean_train_folder=clean_train_folder,
                clean_test_folder=clean_test_folder,
                batch_size=batch_size,
                learning_rate=learning_rate,
                num_epochs=num_epochs,
                verbose=True
            )

            results.append(result)

            if result['success']:
                print(f"âœ… {model_name}: {result['best_val_accuracy']:.2f}% accuracy, F1: {result['best_f1']:.2f}%")
            else:
                print(f"âŒ {model_name}: Failed - {result['error']}")

        # Summary
        print("\nğŸ“ˆ Noise Detection Training Summary:")
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]

        print(f"   Successful: {len(successful)}/{len(results)}")
        print(f"   Failed: {len(failed)}/{len(results)}")

        if successful:
            print("\nğŸ† Best Noise Detectors:")
            successful.sort(key=lambda x: x['best_f1'], reverse=True)
            for i, result in enumerate(successful[:5], 1):
                print(f"   {i}. {result['model_name']}: "
                      f"Acc={result['best_val_accuracy']:.2f}%, "
                      f"F1={result['best_f1']:.2f}%, "
                      f"Precision={result['best_precision']:.2f}%, "
                      f"Recall={result['best_recall']:.2f}%")

        return results
